#!/usr/bin/env python3
# =============================================================================
# å®ä¾‹ï¼šharmonyä»“åº“å¤šåˆ†æ”¯æäº¤èšåˆéªŒè¯è„šæœ¬
# åŠŸèƒ½ï¼šéªŒè¯history-report-2025åˆ†æ”¯ä¸‹3ç±»æ ¸å¿ƒäº§ç‰©æ–‡ä»¶ï¼ˆJSON/Markdown/æ–‡æœ¬ï¼‰çš„åˆè§„æ€§
# ä¾èµ–: requests, python-dotenv (å®‰è£…ï¼špip install requests python-dotenv)
# ä½¿ç”¨è¯´æ˜ï¼š1. é…ç½®.mcp_envæ–‡ä»¶ï¼›2. ç¡®ä¿history-report-2025åˆ†æ”¯å­˜åœ¨ï¼›3. ç›´æ¥è¿è¡Œè„šæœ¬
# =============================================================================

import sys
import os
import requests
import base64
import json
import re
from typing import Dict, Optional, Tuple
from dotenv import load_dotenv


# -----------------------------
# 1) å®ä¾‹åŒ–é…ç½®ï¼ˆå·²æ›¿æ¢ä¸ºå®é™…å€¼ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
CONFIG = {
    "ENV_CONFIG": {
        "github_token_var": "MCP_GITHUB_TOKEN",
        "github_org_var": "GITHUB_EVAL_ORG",
        "env_file": ".mcp_env",
        "root_env_var": "GITHUB_REPO_ROOT"
    },
    "GITHUB_API_CONFIG": {
        "repo_name": "harmony",
        "api_version": "v3",
        "auth_scheme": "Bearer",
        "timeout": 10,
        "per_page": 100
    },
    "BRANCH_CONFIG": {
        "target_branch": "history-report-2025",
        "must_exist": True,
        "base_branch": "main"
    },
    "ARTIFACTS": [
        {
            "name": "BRANCH_COMMITS.json",
            "must_be_in_branch": True,
            "type": "json",
            "format": "json",
            "schema": {
                "min_branches": 3,
                "commit_fields": ["sha", "author", "message", "files_changed"],
                "min_commits_per_branch": 3,
                "json_strict": True
            },
            "content_checks": {
                "expected_branches_source": "HARDCODED",
                "expected_branches": [
                    "pr/45-googlefan256-main",
                    "pr/25-neuralsorcerer-patch-1",
                    "pr/41-amirhosseinghanipour-fix-race-conditions-and-offline-api"
                ],
                "expected_branches_file": "",
                "field_rules": {
                    "sha": {"regex": r"^[0-9a-f]{40}$"},
                    "author": {"min_len": 3},
                    "files_changed": {"type": "int", "min": 1}
                },
                "uniqueness": {
                    "fields": ["sha"],
                    "error_on_duplicate": True
                }
            }
        },
        {
            "name": "CROSS_BRANCH_ANALYSIS.md",
            "must_be_in_branch": True,
            "type": "text",
            "format": "markdown",
            "schema": {
                "required_sections": [
                    "## Top Contributors",
                    "## Branch Commit Summary"
                ],
                "min_length": 500,
                "encoding": "utf-8"
            },
            "content_checks": {
                "must_contain_keywords": [
                    "contributors", "commits", "branch"
                ],
                "expected_contributors": [
                    "scott-oai: 35 commits",
                    "egorsmkv: 4 commits",
                    "axion66: 2 commits"
                ],
                "allow_extra_contributors": True
            }
        },
        {
            "name": "MERGE_TIMELINE.txt",
            "must_be_in_branch": True,
            "type": "text",
            "format": "txt",
            "schema": {
                "line_pattern": r"^\d{4}-\d{2}-\d{2} \| .+ \| [0-9a-f]{40}$",
                "min_lines": 10,
                "date_format": "YYYY-MM-DD"
            },
            "content_checks": {
                "expected_entries_source": "HARDCODED",
                "expected_entries": [
                    "2025-08-06 | Merge pull request #29 from axion66/improve-readme-and-checks | 3efbf742533a375fc148d75513597e139329578b",
                    "2025-08-06 | Merge pull request #30 from Yuan-ManX/harmony-format | 9d653a4c7382abc42d115014d195d9354e7ad357",
                    "2025-08-05 | Merge pull request #26 from jordan-wu-97/jordan/fix-function-call-atomic-bool | 82b3afb9eb043343f322c937262cc50405e892c3"
                ],
                "expected_entries_file": "",
                "allow_extra_entries": True
            }
        }
    ],
    "SOURCE_VALIDATION": {
        "enable": False,
        "source_branches": ["main"],
        "commit_sha_pattern": r"^[0-9a-f]{40}$"
    },
    "POLICY": {
        "forbid_modifying_existing_files": True,
        "only_allow_artifacts": [
            "BRANCH_COMMITS.json",
            "CROSS_BRANCH_ANALYSIS.md",
            "MERGE_TIMELINE.txt"
        ]
    }
}


# -----------------------------
# 2) å·¥å…·å‡½æ•°ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def _load_github_env() -> Tuple[Optional[str], Optional[str]]:
    """åŠ è½½GitHubé‰´æƒç¯å¢ƒå˜é‡ï¼ˆä».mcp_envè¯»å–ï¼‰"""
    load_dotenv(CONFIG["ENV_CONFIG"]["env_file"])
    github_token = os.environ.get(CONFIG["ENV_CONFIG"]["github_token_var"])
    github_org = os.environ.get(CONFIG["ENV_CONFIG"]["github_org_var"])

    if not github_token:
        print(f"âŒ æœªåŠ è½½åˆ°ç¯å¢ƒå˜é‡ {CONFIG['ENV_CONFIG']['github_token_var']}ï¼ˆæ£€æŸ¥{CONFIG['ENV_CONFIG']['env_file']}ï¼‰")
    if not github_org:
        print(f"âŒ æœªåŠ è½½åˆ°ç¯å¢ƒå˜é‡ {CONFIG['ENV_CONFIG']['github_org_var']}ï¼ˆæ£€æŸ¥{CONFIG['ENV_CONFIG']['env_file']}ï¼‰")

    return github_token, github_org


def _build_github_headers(github_token: str) -> Dict[str, str]:
    """æ„å»ºGitHub APIè¯·æ±‚å¤´"""
    return {
        "Authorization": f"{CONFIG['GITHUB_API_CONFIG']['auth_scheme']} {github_token}",
        "Accept": f"application/vnd.github.{CONFIG['GITHUB_API_CONFIG']['api_version']}+json",
        "User-Agent": "harmony-multi-branch-verifier"
    }


def _call_github_api(
    endpoint: str,
    headers: Dict[str, str],
    org: str
) -> Tuple[bool, Optional[Dict]]:
    """è°ƒç”¨GitHub APIï¼ˆæŒ‡å‘harmonyä»“åº“ï¼‰"""
    repo_name = CONFIG["GITHUB_API_CONFIG"]["repo_name"]
    api_url = f"https://api.github.com/repos/{org}/{repo_name}/{endpoint}"

    try:
        response = requests.get(
            api_url,
            headers=headers,
            timeout=CONFIG["GITHUB_API_CONFIG"]["timeout"]
        )

        if response.status_code == 200:
            return True, response.json()
        elif response.status_code == 404:
            print(f"âš ï¸ APIèµ„æºæœªæ‰¾åˆ°ï¼š{endpoint}ï¼ˆ404ï¼‰")
            return False, None
        else:
            print(f"âŒ APIè¯·æ±‚å¤±è´¥ï¼š{endpoint}ï¼ˆçŠ¶æ€ç ï¼š{response.status_code}ï¼‰")
            print(f"   å“åº”å†…å®¹ï¼š{response.text[:200]}")
            return False, None

    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¼‚å¸¸ï¼š{endpoint}ï¼ˆé”™è¯¯ï¼š{str(e)}ï¼‰")
        return False, None


def _check_branch_existence(branch_name: str, headers: Dict[str, str], org: str) -> bool:
    """æ£€æŸ¥ç›®æ ‡åˆ†æ”¯æ˜¯å¦å­˜åœ¨"""
    success, _ = _call_github_api(
        endpoint=f"branches/{branch_name}",
        headers=headers,
        org=org
    )
    if not success and CONFIG["BRANCH_CONFIG"]["must_exist"]:
        print(f"âŒ ç›®æ ‡åˆ†æ”¯ '{branch_name}' ä¸å­˜åœ¨ï¼ˆå¿…éœ€åˆ†æ”¯ï¼Œç»ˆæ­¢éªŒè¯ï¼‰")
        return False
    elif not success:
        print(f"âš ï¸ ç›®æ ‡åˆ†æ”¯ '{branch_name}' ä¸å­˜åœ¨ï¼ˆéå¿…éœ€åˆ†æ”¯ï¼Œç»§ç»­éªŒè¯ï¼‰")
        return True
    print(f"âœ… ç›®æ ‡åˆ†æ”¯ '{branch_name}' å­˜åœ¨")
    return True


def _get_artifact_content(
    branch: str,
    file_name: str,
    headers: Dict[str, str],
    org: str
) -> Optional[str]:
    """ä»ç›®æ ‡åˆ†æ”¯è·å–äº§ç‰©æ–‡ä»¶å†…å®¹ï¼ˆBase64è§£ç ï¼‰"""
    success, file_data = _call_github_api(
        endpoint=f"contents/{file_name}?ref={branch}",
        headers=headers,
        org=org
    )
    if not success or not file_data:
        print(f"âŒ æœªåœ¨åˆ†æ”¯ '{branch}' æ‰¾åˆ°æ–‡ä»¶ '{file_name}'")
        return None

    try:
        base64_content = file_data.get("content", "").replace("\n", "")
        encoding = next(
            art["schema"]["encoding"] for art in CONFIG["ARTIFACTS"] 
            if art["name"] == file_name and "encoding" in art["schema"]
        ) or "utf-8"
        return base64.b64decode(base64_content).decode(encoding)
    except Exception as e:
        print(f"âŒ æ–‡ä»¶ '{file_name}' è§£ç å¤±è´¥ï¼ˆé”™è¯¯ï¼š{str(e)}ï¼‰")
        return None


# -----------------------------
# 3) æ ¸å¿ƒéªŒè¯é€»è¾‘ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def _validate_branch_commits_json(content: str) -> bool:
    """éªŒè¯BRANCH_COMMITS.json"""
    json_artifact = next(art for art in CONFIG["ARTIFACTS"] if art["name"] == "BRANCH_COMMITS.json")
    expected_branches = json_artifact["content_checks"]["expected_branches"]
    commit_fields = json_artifact["schema"]["commit_fields"]
    field_rules = json_artifact["content_checks"]["field_rules"]

    # éªŒè¯JSONè¯­æ³•
    try:
        data = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"âŒ BRANCH_COMMITS.json è¯­æ³•é”™è¯¯ï¼š{str(e)}")
        return False
    print("âœ… BRANCH_COMMITS.json è¯­æ³•éªŒè¯é€šè¿‡")

    # éªŒè¯åˆ†æ”¯æ•°é‡ä¸å­˜åœ¨æ€§
    if len(data) < json_artifact["schema"]["min_branches"]:
        print(f"âŒ åˆ†æ”¯æ•°é‡ä¸è¶³ï¼ˆéœ€â‰¥{json_artifact['schema']['min_branches']}ï¼Œå®é™…ï¼š{len(data)}ï¼‰")
        return False
    missing_branches = [b for b in expected_branches if b not in data]
    if missing_branches:
        print(f"âŒ ç¼ºå¤±é¢„æœŸåˆ†æ”¯ï¼š{', '.join(missing_branches)}")
        return False
    print(f"âœ… åˆ†æ”¯éªŒè¯é€šè¿‡ï¼ˆå…±{len(data)}ä¸ªåˆ†æ”¯ï¼Œå«æ‰€æœ‰é¢„æœŸåˆ†æ”¯ï¼‰")

    # éªŒè¯æäº¤å­—æ®µä¸æ ¼å¼
    sha_set = set()
    valid = True
    for branch, commits in data.items():
        if len(commits) < json_artifact["schema"]["min_commits_per_branch"]:
            print(f"âŒ åˆ†æ”¯ '{branch}' æäº¤ä¸è¶³ï¼ˆéœ€â‰¥3ï¼Œå®é™…ï¼š{len(commits)}ï¼‰")
            valid = False
            continue

        for idx, commit in enumerate(commits, 1):
            # å­—æ®µå®Œæ•´æ€§
            missing_fields = [f for f in commit_fields if f not in commit]
            if missing_fields:
                print(f"âŒ åˆ†æ”¯ '{branch}' ç¬¬{idx}æ¡æäº¤ç¼ºå¤±å­—æ®µï¼š{', '.join(missing_fields)}")
                valid = False
                continue

            # SHAæ ¼å¼ä¸å”¯ä¸€æ€§
            sha = commit["sha"]
            if not re.match(field_rules["sha"]["regex"], sha):
                print(f"âŒ åˆ†æ”¯ '{branch}' ç¬¬{idx}æ¡SHAæ ¼å¼é”™è¯¯ï¼š{sha}")
                valid = False
                continue
            if sha in sha_set:
                print(f"âŒ SHAé‡å¤ï¼š{sha}")
                valid = False
                continue
            sha_set.add(sha)

            # ä½œè€…ä¸æ–‡ä»¶æ•°è§„åˆ™
            if len(commit["author"]) < field_rules["author"]["min_len"]:
                print(f"âŒ åˆ†æ”¯ '{branch}' ç¬¬{idx}æ¡ä½œè€…åè¿‡çŸ­ï¼š{commit['author']}")
                valid = False
                continue
            if not isinstance(commit["files_changed"], int) or commit["files_changed"] < field_rules["files_changed"]["min"]:
                print(f"âŒ åˆ†æ”¯ '{branch}' ç¬¬{idx}æ¡ä¿®æ”¹æ–‡ä»¶æ•°é”™è¯¯ï¼š{commit['files_changed']}")
                valid = False
                continue

    if valid:
        print("âœ… BRANCH_COMMITS.json æäº¤éªŒè¯é€šè¿‡")
    return valid


def _validate_cross_branch_md(content: str) -> bool:
    """éªŒè¯CROSS_BRANCH_ANALYSIS.md"""
    md_artifact = next(art for art in CONFIG["ARTIFACTS"] if art["name"] == "CROSS_BRANCH_ANALYSIS.md")
    required_sections = md_artifact["schema"]["required_sections"]
    expected_contributors = md_artifact["content_checks"]["expected_contributors"]
    keywords = md_artifact["content_checks"]["must_contain_keywords"]

    # éªŒè¯æ–‡æ¡£é•¿åº¦
    if len(content) < md_artifact["schema"]["min_length"]:
        print(f"âŒ æ–‡æ¡£é•¿åº¦ä¸è¶³ï¼ˆéœ€â‰¥{md_artifact['schema']['min_length']}å­—èŠ‚ï¼Œå®é™…ï¼š{len(content)}ï¼‰")
        return False
    print("âœ… æ–‡æ¡£é•¿åº¦éªŒè¯é€šè¿‡")

    # éªŒè¯å¿…éœ€ç« èŠ‚
    missing_sections = [s for s in required_sections if s not in content]
    if missing_sections:
        print(f"âŒ ç¼ºå¤±å¿…éœ€ç« èŠ‚ï¼š{', '.join(missing_sections)}")
        return False
    print("âœ… å¿…éœ€ç« èŠ‚éªŒè¯é€šè¿‡")

    # éªŒè¯å…³é”®è¯
    missing_keywords = [k for k in keywords if k.lower() not in content.lower()]
    if missing_keywords:
        print(f"âŒ ç¼ºå¤±å…³é”®è¯ï¼š{', '.join(missing_keywords)}")
        return False
    print("âœ… å…³é”®è¯éªŒè¯é€šè¿‡")

    # éªŒè¯è´¡çŒ®è€…è®°å½•
    missing_contributors = [c for c in expected_contributors if c not in content]
    if missing_contributors:
        print(f"âŒ ç¼ºå¤±è´¡çŒ®è€…è®°å½•ï¼š{', '.join(missing_contributors)}")
        return False
    print("âœ… è´¡çŒ®è€…è®°å½•éªŒè¯é€šè¿‡")
    return True


def _validate_merge_timeline(content: str) -> bool:
    """éªŒè¯MERGE_TIMELINE.txt"""
    timeline_artifact = next(art for art in CONFIG["ARTIFACTS"] if art["name"] == "MERGE_TIMELINE.txt")
    line_pattern = re.compile(timeline_artifact["schema"]["line_pattern"])
    expected_entries = timeline_artifact["content_checks"]["expected_entries"]
    min_lines = timeline_artifact["schema"]["min_lines"]

    # éªŒè¯æ¡ç›®æ•°é‡
    lines = [l.strip() for l in content.split("\n") if l.strip()]
    if len(lines) < min_lines:
        print(f"âŒ æ—¶é—´çº¿æ¡ç›®ä¸è¶³ï¼ˆéœ€â‰¥{min_lines}ï¼Œå®é™…ï¼š{len(lines)}ï¼‰")
        return False
    print(f"âœ… æ—¶é—´çº¿æ¡ç›®æ•°é‡éªŒè¯é€šè¿‡ï¼ˆå…±{len(lines)}æ¡ï¼‰")

    # éªŒè¯æ ¼å¼
    for idx, line in enumerate(lines, 1):
        if not line_pattern.match(line):
            print(f"âŒ ç¬¬{idx}æ¡æ ¼å¼é”™è¯¯ï¼š{line}")
            print(f"   é¢„æœŸæ ¼å¼ï¼šYYYY-MM-DD | æè¿° | 40ä½SHAï¼ˆå¦‚2025-08-06 | Merge... | 3efbf74...ï¼‰")
            return False
    print("âœ… æ—¶é—´çº¿æ ¼å¼éªŒè¯é€šè¿‡")

    # éªŒè¯é¢„æœŸæ¡ç›®
    missing_entries = [e for e in expected_entries if e not in content]
    if missing_entries:
        print(f"âŒ ç¼ºå¤±é¢„æœŸæ—¶é—´çº¿æ¡ç›®ï¼š{', '.join([e[:50]+'...' for e in missing_entries])}")
        return False
    print("âœ… é¢„æœŸæ—¶é—´çº¿æ¡ç›®éªŒè¯é€šè¿‡")
    return True


def _validate_artifact(content: str, artifact_name: str) -> bool:
    """è·¯ç”±éªŒè¯é€»è¾‘"""
    if artifact_name == "BRANCH_COMMITS.json":
        return _validate_branch_commits_json(content)
    elif artifact_name == "CROSS_BRANCH_ANALYSIS.md":
        return _validate_cross_branch_md(content)
    elif artifact_name == "MERGE_TIMELINE.txt":
        return _validate_merge_timeline(content)
    else:
        print(f"âš ï¸ æœªæ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{artifact_name}ï¼ˆè·³è¿‡ï¼‰")
        return True


# -----------------------------
# 4) ä¸»æµç¨‹ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
# -----------------------------
def main():
    print("ğŸ” å¼€å§‹harmonyä»“åº“å¤šåˆ†æ”¯æäº¤èšåˆéªŒè¯...")
    print("=" * 60)

    # æ­¥éª¤1ï¼šåŠ è½½ç¯å¢ƒ
    print("\nã€æ­¥éª¤1/5ã€‘åŠ è½½GitHubç¯å¢ƒ...")
    github_token, github_org = _load_github_env()
    if not github_token or not github_org:
        print("âŒ ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼ˆç¼ºå¤±ä»¤ç‰Œæˆ–ç»„ç»‡åï¼‰")
        sys.exit(1)
    headers = _build_github_headers(github_token)
    print(f"âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼ˆç»„ç»‡ï¼š{github_org}ï¼Œä»¤ç‰Œå·²åŠ è½½ï¼‰")

    # æ­¥éª¤2ï¼šéªŒè¯ç›®æ ‡åˆ†æ”¯
    print("\nã€æ­¥éª¤2/5ã€‘éªŒè¯ç›®æ ‡åˆ†æ”¯...")
    target_branch = CONFIG["BRANCH_CONFIG"]["target_branch"]
    if not _check_branch_existence(target_branch, headers, github_org):
        sys.exit(1)

    # æ­¥éª¤3ï¼šéªŒè¯äº§ç‰©æ–‡ä»¶
    print("\nã€æ­¥éª¤3/5ã€‘éªŒè¯äº§ç‰©æ–‡ä»¶ï¼ˆå…±3ä¸ªï¼‰...")
    all_valid = True
    for artifact in CONFIG["ARTIFACTS"]:
        print(f"\nğŸ‘‰ éªŒè¯ï¼š{artifact['name']}")
        content = _get_artifact_content(
            branch=target_branch,
            file_name=artifact["name"],
            headers=headers,
            org=github_org
        )
        if not content:
            all_valid = False
            continue
        if not _validate_artifact(content, artifact["name"]):
            all_valid = False
        else:
            print(f"âœ… {artifact['name']} éªŒè¯é€šè¿‡")
    if not all_valid:
        print("\nâŒ éƒ¨åˆ†äº§ç‰©æ–‡ä»¶éªŒè¯å¤±è´¥")
        sys.exit(1)

    # æ­¥éª¤4ï¼šæºæ–‡ä»¶äº¤å‰éªŒè¯ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰
    print("\nã€æ­¥éª¤4/5ã€‘æºæ–‡ä»¶äº¤å‰éªŒè¯...")
    if CONFIG["SOURCE_VALIDATION"]["enable"]:
        print("âš ï¸  æºæ–‡ä»¶éªŒè¯å·²å¯ç”¨ï¼Œéœ€æ‰©å±•å®é™…å¯¹æ¯”é€»è¾‘ï¼ˆå½“å‰ä¸ºå ä½ï¼‰")
        print("âœ… æºæ–‡ä»¶éªŒè¯é€šè¿‡ï¼ˆå ä½ï¼‰")
    else:
        print("âš ï¸  æºæ–‡ä»¶éªŒè¯æœªå¯ç”¨ï¼ˆé…ç½®disable=falseå¯å¼€å¯ï¼‰")
        print("âœ… æºæ–‡ä»¶éªŒè¯æ­¥éª¤è·³è¿‡")

    # æ­¥éª¤5ï¼šç­–ç•¥çº¦æŸæ£€æŸ¥
    print("\nã€æ­¥éª¤5/5ã€‘ç­–ç•¥çº¦æŸæ£€æŸ¥...")
    print(f"âœ… ç¦æ­¢ä¿®æ”¹ä»“åº“æ–‡ä»¶ï¼š{CONFIG['POLICY']['forbid_modifying_existing_files']}")
    print(f"âœ… ä»…å…è®¸éªŒè¯äº§ç‰©ï¼š{', '.join(CONFIG['POLICY']['only_allow_artifacts'])}")
    print("âœ… ç­–ç•¥çº¦æŸéªŒè¯é€šè¿‡")

    # æœ€ç»ˆç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ‰ harmonyä»“åº“å¤šåˆ†æ”¯æäº¤èšåˆéªŒè¯æ‰€æœ‰æ­¥éª¤é€šè¿‡ï¼")
    print(f"ğŸ“‹ éªŒè¯æ±‡æ€»ï¼š")
    print(f"   - ä»“åº“ï¼š{github_org}/harmony")
    print(f"   - åˆ†æ”¯ï¼š{target_branch}")
    print(f"   - äº§ç‰©ï¼šBRANCH_COMMITS.jsonã€CROSS_BRANCH_ANALYSIS.mdã€MERGE_TIMELINE.txt")
    print("=" * 60)
    sys.exit(0)


# -----------------------------
# å…¥å£ï¼ˆæ‰§è¡Œè„šæœ¬ï¼‰
# -----------------------------
if __name__ == "__main__":
    main()
